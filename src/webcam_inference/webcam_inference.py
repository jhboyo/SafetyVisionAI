"""
Real-time PPE Detection using Webcam

Detect helmet, head, and vest in real-time using laptop camera or external webcam.

Usage:
    # Basic usage (laptop camera)
    uv run python src/webcam_inference/webcam_inference.py

    # External webcam
    uv run python src/webcam_inference/webcam_inference.py --camera 1

    # Adjust confidence
    uv run python src/webcam_inference/webcam_inference.py --conf 0.3

    # Custom resolution
    uv run python src/webcam_inference/webcam_inference.py --width 1280 --height 720

Keyboard Controls:
    Q - Quit
    S - Save Screenshot
    P - Pause/Resume
    + - Increase Confidence
    - - Decrease Confidence
    H - Toggle Help
"""

import argparse
import cv2
import numpy as np
from ultralytics import YOLO
from pathlib import Path
import sys
import time
import threading
import tempfile
import os

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

from utils import (
    FPSCounter,
    calculate_statistics_from_results,
    draw_statistics_overlay,
    draw_help_overlay,
    save_screenshot,
    get_available_cameras,
    initialize_camera
)

# ìŒì„± ê²½ê³ ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import (ì„ íƒì )
try:
    from gtts import gTTS  # Google Text-to-Speech: í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
    import pygame  # ì˜¤ë””ì˜¤ ì¬ìƒìš©
    AUDIO_AVAILABLE = True
except ImportError:
    AUDIO_AVAILABLE = False
    print("âš ï¸  ìŒì„± ê²½ê³  ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ gTTSì™€ pygameì„ ì„¤ì¹˜í•˜ì„¸ìš”: pip install gtts pygame")


# ============================================================================
# ìŒì„± ê²½ê³  ì‹œìŠ¤í…œ
# Voice Alert System
# ============================================================================

class VoiceAlertManager:
    """
    AI ìŒì„± ê²½ê³  ì‹œìŠ¤í…œ ë§¤ë‹ˆì €

    PPE ë¯¸ì°©ìš© ê°ì§€ ì‹œ í•œêµ­ì–´ ìŒì„± ê²½ê³ ë¥¼ ì¬ìƒí•©ë‹ˆë‹¤.
    ì¤‘ë³µ ì¬ìƒ ë°©ì§€ë¥¼ ìœ„í•œ ì¿¨ë‹¤ìš´ íƒ€ì´ë¨¸ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
    """

    def __init__(self, cooldown_seconds: int = 10):
        """
        ìŒì„± ê²½ê³  ë§¤ë‹ˆì € ì´ˆê¸°í™”

        Args:
            cooldown_seconds: ê°™ì€ ê²½ê³ ì˜ ì¬ìƒ ê°„ê²© (ì´ˆ, ê¸°ë³¸ê°’: 10ì´ˆ)
        """
        self.cooldown_seconds = cooldown_seconds  # ì¿¨ë‹¤ìš´ ì‹œê°„
        self.last_alert_time = {}  # ë§ˆì§€ë§‰ ê²½ê³  ì‹œê°„ ê¸°ë¡
        self.lock = threading.Lock()  # ìŠ¤ë ˆë“œ ì•ˆì „ì„±ì„ ìœ„í•œ ë½
        self.audio_cache = {}  # ìƒì„±ëœ ìŒì„± íŒŒì¼ ìºì‹œ (ì¬ì‚¬ìš©)

        # gTTSì™€ pygameì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ë¹„í™œì„±í™”
        if not AUDIO_AVAILABLE:
            self.enabled = False
            return

        # pygame mixer ì´ˆê¸°í™” ì‹œë„
        try:
            pygame.mixer.init()
            self.enabled = True
            print("âœ… ìŒì„± ê²½ê³  ì‹œìŠ¤í…œ í™œì„±í™”")
        except Exception as e:
            print(f"âš ï¸  ìŒì„± ê²½ê³  ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.enabled = False

    def _generate_audio(self, text: str, lang: str = 'ko') -> str:
        """
        í…ìŠ¤íŠ¸ë¥¼ ìŒì„± íŒŒì¼ë¡œ ë³€í™˜ (gTTS ì‚¬ìš©)

        Args:
            text: ë³€í™˜í•  í…ìŠ¤íŠ¸ (ì˜ˆ: "ì•ˆì „ëª¨ë¥¼ ì°©ìš©í•˜ì„¸ìš”")
            lang: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: 'ko' í•œêµ­ì–´)

        Returns:
            str: ìƒì„±ëœ ìŒì„± íŒŒì¼ ê²½ë¡œ (mp3), ì‹¤íŒ¨ ì‹œ None
        """
        # ìºì‹œ í™•ì¸ (ë™ì¼í•œ í…ìŠ¤íŠ¸ëŠ” ì¬ìƒì„±í•˜ì§€ ì•Šê³  ì¬ì‚¬ìš©)
        cache_key = f"{text}_{lang}"
        if cache_key in self.audio_cache:
            return self.audio_cache[cache_key]

        try:
            # Google TTSë¡œ ìŒì„± ìƒì„±
            tts = gTTS(text=text, lang=lang, slow=False)

            # ì‹œìŠ¤í…œ ì„ì‹œ ë””ë ‰í† ë¦¬ì— mp3 íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as fp:
                temp_path = fp.name
                tts.save(temp_path)

            # ìºì‹œì— ì €ì¥ (ë‹¤ìŒë²ˆ ì¬ì‚¬ìš©)
            self.audio_cache[cache_key] = temp_path
            return temp_path

        except Exception as e:
            print(f"âš ï¸  ìŒì„± ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def play_alert(self, alert_type: str, force: bool = False):
        """
        ìŒì„± ê²½ê³  ì¬ìƒ (ì¿¨ë‹¤ìš´ íƒ€ì´ë¨¸ ì ìš©)

        Args:
            alert_type: ê²½ê³  ìœ í˜•
                - 'helmet': "ì•ˆì „ëª¨ë¥¼ ì°©ìš©í•˜ì„¸ìš”"
                - 'vest': "ì•ˆì „ ì¡°ë¼ë¥¼ ì°©ìš©í•˜ì„¸ìš”"
                - 'danger': "ìœ„í—˜! ì•ˆì „ ì¥ë¹„ë¥¼ ì°©ìš©í•˜ì„¸ìš”"
            force: Trueì¼ ê²½ìš° ì¿¨ë‹¤ìš´ ë¬´ì‹œí•˜ê³  ê°•ì œ ì¬ìƒ (ê¸°ë³¸ê°’: False)
        """
        if not self.enabled:
            return

        # ì¿¨ë‹¤ìš´ ì²´í¬ (ìŠ¤ë ˆë“œ ì•ˆì „)
        with self.lock:
            current_time = time.time()
            last_time = self.last_alert_time.get(alert_type, 0)

            # ì¿¨ë‹¤ìš´ ì‹œê°„ì´ ì§€ë‚˜ì§€ ì•Šì•˜ìœ¼ë©´ ì¬ìƒí•˜ì§€ ì•ŠìŒ
            if not force and (current_time - last_time) < self.cooldown_seconds:
                return

            # ë§ˆì§€ë§‰ ì¬ìƒ ì‹œê°„ ì—…ë°ì´íŠ¸
            self.last_alert_time[alert_type] = current_time

        # ê²½ê³  ìœ í˜•ì— ë”°ë¥¸ ë©”ì‹œì§€ ì„ íƒ
        messages = {
            'helmet': 'ì•ˆì „ëª¨ë¥¼ ì°©ìš©í•˜ì„¸ìš”',
            'vest': 'ì•ˆì „ ì¡°ë¼ë¥¼ ì°©ìš©í•˜ì„¸ìš”',
            'danger': 'ìœ„í—˜! ì•ˆì „ ì¥ë¹„ë¥¼ ì°©ìš©í•˜ì„¸ìš”'
        }
        message = messages.get(alert_type, 'ì•ˆì „ ìˆ˜ì¹™ì„ ì¤€ìˆ˜í•˜ì„¸ìš”')

        # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì¬ìƒ (ë©”ì¸ ìŠ¤ë ˆë“œê°€ ì°¨ë‹¨ë˜ì§€ ì•Šë„ë¡)
        thread = threading.Thread(
            target=self._play_audio_thread,
            args=(message,),
            daemon=True  # ë©”ì¸ í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ìë™ ì¢…ë£Œ
        )
        thread.start()

    def _play_audio_thread(self, text: str):
        """
        ìŒì„± ì¬ìƒ ìŠ¤ë ˆë“œ (ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ë˜ëŠ” ë‚´ë¶€ ë©”ì„œë“œ)

        macOSì—ì„œëŠ” afplayë¥¼ ì‚¬ìš©í•˜ê³ , ë‹¤ë¥¸ OSì—ì„œëŠ” pygameì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        afplayê°€ ë” ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•˜ê¸° ë•Œë¬¸ì— macOSì—ì„œëŠ” ì´ë¥¼ ìš°ì„  ì‚¬ìš©í•©ë‹ˆë‹¤.

        Args:
            text: ì¬ìƒí•  í…ìŠ¤íŠ¸ (ì˜ˆ: "ì•ˆì „ëª¨ë¥¼ ì°©ìš©í•˜ì„¸ìš”")
        """
        try:
            # ìŒì„± íŒŒì¼ ìƒì„± ë˜ëŠ” ìºì‹œì—ì„œ ê°€ì ¸ì˜¤ê¸°
            audio_path = self._generate_audio(text)
            if audio_path and os.path.exists(audio_path):
                import platform
                import subprocess

                # macOSì¸ ê²½ìš° afplay ëª…ë ¹ì–´ ì‚¬ìš© (ì‹œìŠ¤í…œ ê¸°ë³¸ ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´)
                if platform.system() == 'Darwin':
                    print(f"ğŸ”Š ìŒì„± ì¬ìƒ: {text}")
                    subprocess.run(['afplay', audio_path], check=False)
                else:
                    # Windows/Linuxì—ì„œëŠ” pygame ì‚¬ìš©
                    pygame.mixer.music.load(audio_path)
                    pygame.mixer.music.play()

                    # ì¬ìƒì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
                    while pygame.mixer.music.get_busy():
                        time.sleep(0.1)

        except Exception as e:
            print(f"âš ï¸  ìŒì„± ì¬ìƒ ì‹¤íŒ¨: {e}")

    def cleanup(self):
        """
        ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ë° ì„ì‹œ íŒŒì¼ ì‚­ì œ

        í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ í˜¸ì¶œí•˜ì—¬ ìƒì„±ëœ ëª¨ë“  ì„ì‹œ ìŒì„± íŒŒì¼ì„ ì‚­ì œí•©ë‹ˆë‹¤.
        """
        # pygame mixer ì¢…ë£Œ
        if self.enabled:
            pygame.mixer.quit()

        # ìºì‹œëœ ëª¨ë“  ì„ì‹œ ìŒì„± íŒŒì¼ ì‚­ì œ
        for path in self.audio_cache.values():
            try:
                if os.path.exists(path):
                    os.remove(path)
            except:
                pass  # ì‚­ì œ ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ

        self.audio_cache.clear()


# ============================================================================
# ë©”ì¸ ì‹¤ì‹œê°„ ì¶”ë¡  í•¨ìˆ˜
# Main Real-time Inference Function
# ============================================================================

def run_realtime_inference(
    camera_id: int = 0,
    model_path: Path = None,
    conf_threshold: float = 0.25,
    width: int = None,
    height: int = None,
    output_dir: Path = None,
    enable_voice_alert: bool = True
):
    """
    ì‹¤ì‹œê°„ PPE íƒì§€ ìˆ˜í–‰

    Args:
        camera_id: ì¹´ë©”ë¼ ì¸ë±ìŠ¤ (0: ë…¸íŠ¸ë¶ ë‚´ì¥, 1: ì™¸ë¶€ ì›¹ìº )
        model_path: YOLO ëª¨ë¸ ê²½ë¡œ
        conf_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
        width: í•´ìƒë„ ë„ˆë¹„
        height: í•´ìƒë„ ë†’ì´
        output_dir: ìŠ¤í¬ë¦°ìƒ· ì €ì¥ ë””ë ‰í† ë¦¬
        enable_voice_alert: ìŒì„± ê²½ê³  í™œì„±í™” ì—¬ë¶€
    """
    print("="*80)
    print("PPE Detection - Real-time Webcam Inference")
    print("="*80)
    print(f"Camera: {camera_id}")
    print(f"Model: {model_path}")
    print(f"Confidence Threshold: {conf_threshold}")
    if width and height:
        print(f"Resolution: {width}x{height}")
    print("="*80)
    print()

    # ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ í™•ì¸
    available_cameras = get_available_cameras()
    print(f"Available cameras: {available_cameras}")

    if camera_id not in available_cameras:
        print(f"Error: Camera {camera_id} is not available.")
        print(f"Please use one of: {available_cameras}")
        return

    # ëª¨ë¸ ë¡œë“œ
    print("\nLoading YOLO model...")
    try:
        model = YOLO(str(model_path))
        print("Model loaded successfully!")
    except Exception as e:
        print(f"Error loading model: {e}")
        return

    # ì¹´ë©”ë¼ ì´ˆê¸°í™”
    print(f"\nInitializing camera {camera_id}...")
    try:
        cap = initialize_camera(camera_id, width, height)
        print("Camera initialized successfully!")
    except Exception as e:
        print(f"Error initializing camera: {e}")
        return

    # ì‹¤ì œ í•´ìƒë„ í™•ì¸
    actual_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    actual_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    print(f"Camera resolution: {actual_width}x{actual_height}")

    # FPS ì¹´ìš´í„° ì´ˆê¸°í™”
    fps_counter = FPSCounter(window_size=30)

    # ìŒì„± ê²½ê³  ë§¤ë‹ˆì € ì´ˆê¸°í™”
    voice_manager = None
    if enable_voice_alert and AUDIO_AVAILABLE:
        voice_manager = VoiceAlertManager(cooldown_seconds=10)
        if voice_manager.enabled:
            print("ğŸ”Š ìŒì„± ê²½ê³  ì‹œìŠ¤í…œ í™œì„±í™”ë¨")
        else:
            voice_manager = None
            print("âš ï¸  ìŒì„± ê²½ê³  ì‹œìŠ¤í…œ ë¹„í™œì„±í™”ë¨")
    elif enable_voice_alert and not AUDIO_AVAILABLE:
        print("âš ï¸  ìŒì„± ê²½ê³  ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ gTTSì™€ pygameì„ ì„¤ì¹˜í•˜ì„¸ìš”")

    # ìƒíƒœ ë³€ìˆ˜
    paused = False
    show_help = False
    current_conf = conf_threshold

    print("\n" + "="*80)
    print("Starting real-time inference...")
    print("Press 'H' for keyboard controls")
    print("="*80 + "\n")

    # ë©”ì¸ ë£¨í”„
    frame_count = 0
    try:
        while True:
            # ì¼ì‹œì •ì§€ ìƒíƒœê°€ ì•„ë‹ ë•Œë§Œ í”„ë ˆì„ ì½ê¸°
            if not paused:
                ret, frame = cap.read()
                if not ret:
                    print("Error: Failed to read frame from camera")
                    break

                frame_count += 1

                # YOLO ì¶”ë¡  ìˆ˜í–‰
                results = model(frame, conf=current_conf, verbose=False)

                # ê²°ê³¼ ì‹œê°í™” (ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°)
                annotated_frame = results[0].plot()

                # í†µê³„ ê³„ì‚° (helmet, head, vest ê°œìˆ˜ ë° ì°©ìš©ë¥ )
                stats = calculate_statistics_from_results(results)

                # ì•ˆì „ ìˆ˜ì¤€ í‰ê°€ ë° ìŒì„± ê²½ê³ 
                if voice_manager and stats['total_workers'] > 0:
                    helmet_rate = stats['helmet_rate']
                    head_count = stats['head_count']

                    # ìœ„í—˜ ìˆ˜ì¤€ (ì°©ìš©ë¥  70% ë¯¸ë§Œ)
                    if helmet_rate < 70:
                        if head_count >= 2:
                            # 2ëª… ì´ìƒ ë¯¸ì°©ìš© ì‹œ ìœ„í—˜ ê²½ê³ 
                            voice_manager.play_alert('danger')
                        elif head_count > 0:
                            # 1ëª… ë¯¸ì°©ìš© ì‹œ í—¬ë©§ ê²½ê³ 
                            voice_manager.play_alert('helmet')
                    # ì£¼ì˜ ìˆ˜ì¤€ (ì°©ìš©ë¥  70-90%)
                    elif helmet_rate < 90:
                        if head_count > 0:
                            voice_manager.play_alert('helmet')

                # FPS ì—…ë°ì´íŠ¸
                fps = fps_counter.update()

                # í†µê³„ ì˜¤ë²„ë ˆì´ ì¶”ê°€
                display_frame = draw_statistics_overlay(
                    annotated_frame, stats, fps, current_conf
                )
            else:
                # ì¼ì‹œì •ì§€ ìƒíƒœì—ì„œëŠ” ê¸°ì¡´ í”„ë ˆì„ ì‚¬ìš©
                display_frame = annotated_frame.copy()

                # ì¼ì‹œì •ì§€ ë©”ì‹œì§€ í‘œì‹œ
                height, width = display_frame.shape[:2]
                cv2.putText(
                    display_frame, "PAUSED (Press P to resume)",
                    (width // 2 - 200, height // 2),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.0,
                    (0, 255, 255), 2
                )

            # ë„ì›€ë§ ì˜¤ë²„ë ˆì´ (H í‚¤ ëˆ„ë¦„)
            if show_help:
                display_frame = draw_help_overlay(display_frame)

            # í™”ë©´ í‘œì‹œ
            cv2.imshow('PPE Detection - Real-time', display_frame)

            # í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬
            key = cv2.waitKey(1) & 0xFF

            if key == ord('q') or key == ord('Q'):
                # ì¢…ë£Œ
                print("\nQuitting...")
                break

            elif key == ord('s') or key == ord('S'):
                # ìŠ¤í¬ë¦°ìƒ· ì €ì¥
                filepath = save_screenshot(display_frame, str(output_dir))
                print(f"Screenshot saved: {filepath}")

            elif key == ord('p') or key == ord('P'):
                # ì¼ì‹œì •ì§€/ì¬ê°œ
                paused = not paused
                status = "paused" if paused else "resumed"
                print(f"Video {status}")

            elif key == ord('h') or key == ord('H'):
                # ë„ì›€ë§ í† ê¸€
                show_help = not show_help

            elif key == ord('+') or key == ord('='):
                # ì‹ ë¢°ë„ ì¦ê°€
                current_conf = min(current_conf + 0.05, 0.95)
                print(f"Confidence threshold: {current_conf:.2f}")

            elif key == ord('-') or key == ord('_'):
                # ì‹ ë¢°ë„ ê°ì†Œ
                current_conf = max(current_conf - 0.05, 0.05)
                print(f"Confidence threshold: {current_conf:.2f}")

            elif key == ord('v') or key == ord('V'):
                # ê°•ì œ ìŒì„± í…ŒìŠ¤íŠ¸ (ë””ë²„ê¹…ìš©)
                if voice_manager:
                    print("ğŸ”Š ê°•ì œ ìŒì„± í…ŒìŠ¤íŠ¸: 'helmet' ê²½ê³  ì¬ìƒ")
                    voice_manager.play_alert('helmet', force=True)
                else:
                    print("âš ï¸  ìŒì„± ë§¤ë‹ˆì €ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤")

    except KeyboardInterrupt:
        print("\n\nInterrupted by user")

    finally:
        # ë¦¬ì†ŒìŠ¤ í•´ì œ
        print("\nReleasing resources...")

        # ìŒì„± ë§¤ë‹ˆì € ì •ë¦¬
        if voice_manager:
            voice_manager.cleanup()

        cap.release()
        cv2.destroyAllWindows()

        # ìµœì¢… í†µê³„ ì¶œë ¥
        print("\n" + "="*80)
        print("Session Summary")
        print("="*80)
        print(f"Total frames processed: {frame_count}")
        print(f"Average FPS: {fps_counter.get_fps():.1f}")
        print("="*80)
        print("\nThank you for using PPE Detection System!")


# ============================================================================
# ì»¤ë§¨ë“œë¼ì¸ ì¸í„°í˜ì´ìŠ¤
# Command-Line Interface
# ============================================================================

def parse_args():
    """ì»¤ë§¨ë“œë¼ì¸ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(
        description='Real-time PPE Detection using Webcam',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Laptop camera
  python webcam_inference.py

  # External webcam
  python webcam_inference.py --camera 1

  # Adjust confidence
  python webcam_inference.py --conf 0.3

  # Custom resolution
  python webcam_inference.py --width 1280 --height 720

Keyboard Controls:
  Q - Quit
  S - Save Screenshot
  P - Pause/Resume
  + - Increase Confidence
  - - Decrease Confidence
  H - Toggle Help
        """
    )

    parser.add_argument(
        '--camera', '-c',
        type=int,
        default=0,
        help='Camera index (0: laptop, 1: external webcam)'
    )

    parser.add_argument(
        '--model', '-m',
        type=str,
        default=None,
        help='Model file path (default: models/ppe_detection/weights/best.pt)'
    )

    parser.add_argument(
        '--conf',
        type=float,
        default=0.25,
        help='Confidence threshold (default: 0.25)'
    )

    parser.add_argument(
        '--width', '-w',
        type=int,
        default=None,
        help='Camera width resolution'
    )

    parser.add_argument(
        '--height', '-ht',
        type=int,
        default=None,
        help='Camera height resolution'
    )

    parser.add_argument(
        '--output', '-o',
        type=str,
        default=None,
        help='Screenshot output directory (default: output/webcam_screenshots)'
    )

    parser.add_argument(
        '--voice-alert',
        action='store_true',
        default=True,
        help='Enable voice alert for safety warnings (default: True)'
    )

    parser.add_argument(
        '--no-voice-alert',
        dest='voice_alert',
        action='store_false',
        help='Disable voice alert'
    )

    return parser.parse_args()


# ============================================================================
# ë©”ì¸ í•¨ìˆ˜
# Main Function
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    args = parse_args()

    # í”„ë¡œì íŠ¸ ê¸°ë³¸ ë””ë ‰í† ë¦¬ (src/webcam_inference/webcam_inference.py)
    base_dir = Path(__file__).parent.parent.parent

    # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
    if args.model:
        model_path = Path(args.model)
        if not model_path.is_absolute():
            model_path = base_dir / model_path
    else:
        model_path = base_dir / 'models' / 'ppe_detection' / 'weights' / 'best.pt'

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if args.output:
        output_dir = Path(args.output)
        if not output_dir.is_absolute():
            output_dir = base_dir / output_dir
    else:
        output_dir = base_dir / 'output' / 'webcam_screenshots'

    # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not model_path.exists():
        print(f"Error: Model file not found: {model_path}")
        print("\nPlease ensure the model file exists or specify the correct path using --model")
        return

    # ì‹¤ì‹œê°„ ì¶”ë¡  ì‹¤í–‰
    try:
        run_realtime_inference(
            camera_id=args.camera,
            model_path=model_path,
            conf_threshold=args.conf,
            width=args.width,
            height=args.height,
            output_dir=output_dir,
            enable_voice_alert=args.voice_alert
        )
    except Exception as e:
        print(f"\nError occurred: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
